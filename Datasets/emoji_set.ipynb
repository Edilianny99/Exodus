{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  tweet sentimiento\n",
      "2974  que respeten nuestra bandera esos que dicen es...         ira\n",
      "1232  sabe todo simple y tiene textura rara ü§¢ compre...        asco\n",
      "1726          que rabia cuando comen mani cerca m√≠oü§¢ü§¢ü§¢ü§¢        asco\n",
      "5160  la universidad y la pandemia van a acabar con ...    tristeza\n",
      "3740  la reina de la tecnocarrilera marbelle no deja...       miedo\n",
      "2789  sin luz pueblo nuevo av la palma en tinaquillo...         ira\n",
      "1818                                          grosera ü§Æ        asco\n",
      "2711                        pero esa caraja es casada üò§         ira\n",
      "2791                                      q defensita üò§         ira\n",
      "1479  yo creo que les recetearon el disco... dios lo...        asco\n",
      "2632  en lo q tengo d ser morada cruz ha sido el m√°s...         ira\n",
      "1631     el codazo lo pegaba uno de junior y era roja ü§Æ        asco\n",
      "1125          apetito voraz el del gobierno anterior ü§¢ü§Æ        asco\n",
      "4353                                mk que t√≥xica soy ü§Ø    sorpresa\n",
      "26    mi vieja anoche fue a buscar a guada a su casa...     alegria\n",
      "4346         lo sigo cantando.. üòÇü§£üòÇü§£üòÇÔ∏è.... lo m√°ximo...    sorpresa\n",
      "3675   igual que los de la hija de la procuradora?? üò±üòÇÔ∏è       miedo\n",
      "4037  esa tal valecitahu se nota a leguas que estaba...    sorpresa\n",
      "896                                    am√©n am√©n am√©n üòá     alegria\n",
      "3826                                       apag√≥n.? üò±üò±üò±       miedo\n"
     ]
    }
   ],
   "source": [
    "archivo=\"Emojis_clean_corregido.csv\"\n",
    "\n",
    "# Leer el archivo que est√° separado por comas\n",
    "df = pd.read_csv(archivo, delimiter=\",\")  # Prueba con delimiter=\",\" si es un archivo CSV est√°ndar\n",
    "\n",
    "# Mostrar una muestra aleatoria de 5 filas\n",
    "print(df.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         id                 created_at        username  \\\n",
      "73528   1539816213357875201  2022-06-23 03:42:48+00:00        odjuan27   \n",
      "133984  1551864606183882752  2022-07-26 09:38:49+00:00   cherrybooomxx   \n",
      "11409   1552265207422091266  2022-07-27 12:10:39+00:00  carlitos_edu26   \n",
      "48461   1412484290689048587  2021-07-06 18:51:12+00:00  zirtaebzeravla   \n",
      "28431   1437555635873267715  2021-09-13 23:15:46+00:00   amarincardozo   \n",
      "\n",
      "                                                    tweet  \n",
      "73528   Una de las ventajas de salir con un odont√≥logo...  \n",
      "133984                         Todo est√° saliendo bieeenüòç  \n",
      "11409   Pensando con mis dos a√±os que me iba a vacilar...  \n",
      "48461   @GUSTSRAMON6664 Ser√° que te portas mal, y por ...  \n",
      "28431   @lord_nutrition 1 2 3 se call√≥ esa ni√±a hay üôàü§¶...  \n",
      "El dataset original tiene 144218 filas.\n",
      "Muestra de 1000 comentarios:\n",
      "                         id                 created_at        username  \\\n",
      "71046   1560050461830414336  2022-08-17 23:46:29+00:00         JUDIN27   \n",
      "25781   1548383128326090753  2022-07-16 19:04:40+00:00       mairym888   \n",
      "45222   1561045552195837953  2022-08-20 17:40:37+00:00  CValentina2410   \n",
      "138720  1404765167653634054  2021-06-15 11:38:09+00:00       Nepxander   \n",
      "12548   1538172170773401600  2022-06-18 14:49:58+00:00     walterfossi   \n",
      "\n",
      "                                                    tweet  \n",
      "71046   @DoctorRenny ü§î la pelua tiene cara de consenti...  \n",
      "25781   @Eugyn3 Felices estamos!   ü•†           Comimos...  \n",
      "45222                        @TestAccountDev4 Muy bueno üòÑ  \n",
      "138720  En ese momento cell, se derriti√≥.üòç https://t.c...  \n",
      "12548   @maferarevalo3 Yo nunca lo he fumado! De echo ...  \n",
      "Se ha guardado la muestra en 'EmojisAlegria_muestra.csv'.\n"
     ]
    }
   ],
   "source": [
    "archivo=\"C:/Users/edili/Downloads/Data-Collection-main/Data-Collection-main/Data-CSV/crudo_V1/raw-emoji-set/EmojisAlegria\"\n",
    "\n",
    "# Leer el archivo asumiendo que est√° separado por comas\n",
    "df = pd.read_csv(archivo, delimiter=\",\")  # Prueba con delimiter=\",\" si es un archivo CSV est√°ndar\n",
    "\n",
    "# Mostrar una muestra aleatoria de 5 filas\n",
    "print(df.sample(5))\n",
    "\n",
    "# Mostrar el tama√±o del archivo original\n",
    "print(f\"El dataset original tiene {len(df)} filas.\")\n",
    "\n",
    "# Extraer una muestra aleatoria de 1000 filas (si el archivo tiene m√°s de 1000 filas)\n",
    "df_muestra = df.sample(n=1000, random_state=42) if len(df) >= 1000 else df\n",
    "\n",
    "# Mostrar una muestra del dataset extra√≠do\n",
    "print(\"Muestra de 1000 comentarios:\")\n",
    "print(df_muestra.head())\n",
    "\n",
    "# Guardar la muestra en un nuevo archivo CSV\n",
    "df_muestra.to_csv(\"EmojisAlegria_muestra.csv\", index=False)\n",
    "print(\"Se ha guardado la muestra en 'EmojisAlegria_muestra.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrajo muestra del archivo EmojisAlegr√≠a, se trajo 1000 de 144.218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id                 created_at         username  \\\n",
      "4636   1478009718333444101  2022-01-03 14:25:51+00:00        Liyisleal   \n",
      "8942   1557791694497746948  2022-08-11 18:10:56+00:00     jenrique2494   \n",
      "27245  1361140259166248962  2021-02-15 02:28:21+00:00  calberguezyahoo   \n",
      "18852  1378789266420084738  2021-04-04 19:19:12+00:00        yaveth_16   \n",
      "2262   1504630718449733638  2022-03-18 01:28:12+00:00      TriciaKenia   \n",
      "\n",
      "                                                   tweet  \n",
      "4636                    Es que la gente es s√∫per sab√≠a üòû  \n",
      "8942   La psic√≥loga me acaba de echar el carro, me de...  \n",
      "27245  @Frankia25Elena @RafaelE04675928 @herbinhoyos ...  \n",
      "18852  @alejcolinam Te entiendo tanto , momento de cu...  \n",
      "2262   @mv_negra2 @josegarcia947 @MovCi21N @MENSAJERO...  \n",
      "El dataset original tiene 27887 filas.\n",
      "Muestra de 1000 comentarios:\n",
      "                        id                 created_at        username  \\\n",
      "21331  1379147696104149000  2021-04-05 19:03:28+00:00     willdrums05   \n",
      "19478  1358216868138541057  2021-02-07 00:51:50+00:00          YofaDz   \n",
      "10413  1499923097931165696  2022-03-05 01:41:48+00:00  Lilianadavilam   \n",
      "25391  1352677269697916928  2021-01-22 17:59:27+00:00       lukasbp__   \n",
      "7676   1560421185246175233  2022-08-19 00:19:36+00:00        cesarAM_   \n",
      "\n",
      "                                                   tweet  \n",
      "21331                  @bostonrex Aaahh que triste bro üòï  \n",
      "19478  S√°bado de Pre-Carnaval y yo acostadaüò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠...  \n",
      "10413  @erikmijaress La triste historia de una enga√±a...  \n",
      "25391                Odio tomarme fotos para documentosüò£  \n",
      "7676   Mi d√≠a iba perfecto @Casemiro por que nos hace...  \n",
      "Se ha guardado la muestra en 'EmojisAlegria_muestra.csv'.\n"
     ]
    }
   ],
   "source": [
    "archivo=\"C:/Users/edili/Downloads/Data-Collection-main/Data-Collection-main/Data-CSV/crudo_V1/raw-emoji-set/EmojisTristeza\"\n",
    "\n",
    "# Leer el archivo asumiendo que est√° separado por comas\n",
    "df = pd.read_csv(archivo, delimiter=\",\")  # Prueba con delimiter=\",\" si es un archivo CSV est√°ndar\n",
    "\n",
    "# Mostrar una muestra aleatoria de 5 filas\n",
    "print(df.sample(5))\n",
    "\n",
    "# Mostrar el tama√±o del archivo original\n",
    "print(f\"El dataset original tiene {len(df)} filas.\")\n",
    "\n",
    "# Extraer una muestra aleatoria de 1000 filas (si el archivo tiene m√°s de 1000 filas)\n",
    "df_muestra = df.sample(n=1000, random_state=42) if len(df) >= 1000 else df\n",
    "\n",
    "# Mostrar una muestra del dataset extra√≠do\n",
    "print(\"Muestra de 1000 comentarios:\")\n",
    "print(df_muestra.head())\n",
    "\n",
    "# Guardar la muestra en un nuevo archivo CSV\n",
    "df_muestra.to_csv(\"EmojisTristeza_muestra.csv\", index=False)\n",
    "print(\"Se ha guardado la muestra en 'EmojisTristeza_muestra.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrajo muestra aleatoria del archivo EmojisTristeza, se trajo 1000 de 27.887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id                 created_at        username  \\\n",
      "16418  1561664375420817416  2022-08-22 10:39:36+00:00   AlfonsoTobon4   \n",
      "13887  1561706588884410368  2022-08-22 13:27:20+00:00    DiegoMilitoG   \n",
      "9338   1561182235432189952  2022-08-21 02:43:44+00:00  nicolasshhhhhh   \n",
      "12631  1562610781555789826  2022-08-25 01:20:16+00:00     CarolG_1111   \n",
      "4392   1285096500448698368  2020-07-20 06:17:36+00:00  mariafibarguen   \n",
      "\n",
      "                                                   tweet  \n",
      "16418  @JuliaCorreaNutt √âsta uribestia hijueputa defi...  \n",
      "13887  Que tongo le metieron a @LokilloFlorez en su p...  \n",
      "9338                    Que aberraci√≥n es el four lokoü§Æü§Æ  \n",
      "12631  @RevistaSemana Que porquer√≠a ü§Æü§Æü§Æü§Æ pero la dere...  \n",
      "4392     A la @Yeinysanchez la estoy dejando quieta üòÇüòÇüòÇü§Æ  \n",
      "El dataset original tiene 17414 filas.\n",
      "Muestra de 1000 comentarios:\n",
      "                        id                 created_at         username  \\\n",
      "14097  1561471292280393729  2022-08-21 21:52:21+00:00      EdnaMalambo   \n",
      "10978  1561752774626484226  2022-08-22 16:30:52+00:00        efarinc28   \n",
      "7408   1560605181070307328  2022-08-19 12:30:44+00:00    lalieverytime   \n",
      "6375   1265490600670957569  2020-05-27 03:50:45+00:00  pedropmanjarres   \n",
      "6874   1250224495228583938  2020-04-15 00:48:42+00:00     _Juliana2710   \n",
      "\n",
      "                                                   tweet  \n",
      "14097      Ese Juan David se come un vomito ü§Æ ü§¢ü§¢ü§Æü§Æüò°üò°üò°üò°üò°üò°  \n",
      "10978  @2fly4most @KhabyLame Se nota que eres una per...  \n",
      "7408   So√±e q me com√≠a un paquete entero de chocolina...  \n",
      "6375   Verdad que cuando uno no tiene sed el agua sab...  \n",
      "6874   Habr√° alguien que no elimine esa horrible cost...  \n",
      "Se ha guardado la muestra en 'EmojisAsco_muestra.csv'.\n"
     ]
    }
   ],
   "source": [
    "archivo=\"C:/Users/edili/Downloads/Data-Collection-main/Data-Collection-main/Data-CSV/crudo_V1/raw-emoji-set/EmojisAsco\"\n",
    "\n",
    "# Leer el archivo asumiendo que est√° separado por comas\n",
    "df = pd.read_csv(archivo, delimiter=\",\")  # Prueba con delimiter=\",\" si es un archivo CSV est√°ndar\n",
    "\n",
    "# Mostrar una muestra aleatoria de 5 filas\n",
    "print(df.sample(5))\n",
    "\n",
    "# Mostrar el tama√±o del archivo original\n",
    "print(f\"El dataset original tiene {len(df)} filas.\")\n",
    "\n",
    "# Extraer una muestra aleatoria de 1000 filas (si el archivo tiene m√°s de 1000 filas)\n",
    "df_muestra = df.sample(n=1000, random_state=42) if len(df) >= 1000 else df\n",
    "\n",
    "# Mostrar una muestra del dataset extra√≠do\n",
    "print(\"Muestra de 1000 comentarios:\")\n",
    "print(df_muestra.head())\n",
    "\n",
    "# Guardar la muestra en un nuevo archivo CSV\n",
    "df_muestra.to_csv(\"EmojisAsco_muestra.csv\", index=False)\n",
    "print(\"Se ha guardado la muestra en 'EmojisAsco_muestra.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrajo muestra aleatoria del archivo EmojisAsco, se trajo 1000 de 17.414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id                 created_at       username  \\\n",
      "17476  1354611697357565952  2021-01-28 02:06:10+00:00  HECTOR_MESA_Z   \n",
      "1033   1559182966324137985  2022-08-15 14:19:22+00:00        edumrgl   \n",
      "11552  1382822455757185026  2021-04-15 22:25:39+00:00  dayannidely07   \n",
      "16352  1382044313807425547  2021-04-13 18:53:36+00:00      OscarEduu   \n",
      "19120  1388303951435636744  2021-05-01 01:27:10+00:00   w_diazperaza   \n",
      "\n",
      "                                                   tweet  \n",
      "17476  Soy solo yo o alguien tambi√©n cree que las \"di...  \n",
      "1033     @sturlinares @AzaOrdom As√≠ es, asco de gente üò°üò°  \n",
      "11552  1. No me acuerdo. \\n2. Te dije que no me acuer...  \n",
      "16352  Me puede faltar cualquier vaina menos una arre...  \n",
      "19120                   Soy demasiadamente JODIDA !! üí•‚ò†Ô∏è  \n",
      "El dataset original tiene 21968 filas.\n",
      "Muestra de 1000 comentarios:\n",
      "                        id                 created_at         username  \\\n",
      "11584  1382393315862122505  2021-04-14 18:00:24+00:00      smartintell   \n",
      "12107  1377456374125330432  2021-04-01 03:02:46+00:00         MaFeLaGz   \n",
      "16416  1380318263880650754  2021-04-09 00:34:53+00:00     juankelgordo   \n",
      "17614  1351189832605831173  2021-01-18 15:28:54+00:00          boscill   \n",
      "5995   1361399372764823555  2021-02-15 19:37:58+00:00  lauraesperanza7   \n",
      "\n",
      "                                                   tweet  \n",
      "11584              Qu√© tal???üò°üò°üò° https://t.co/7Gl8xibjTr  \n",
      "12107  @AfiniaGrupoEPM  Quue ganas  las que me dan de...  \n",
      "16416  Alcalde payaso!!! Jugando con la opini√≥n p√∫bli...  \n",
      "17614  @vzlaencontacto Todo es un negocio redondo, in...  \n",
      "5995   Y ni hablar de la situaci√≥n sanitaria por el c...  \n",
      "Se ha guardado la muestra en 'EmojisIra_muestra.csv'.\n"
     ]
    }
   ],
   "source": [
    "archivo=\"C:/Users/edili/Downloads/Data-Collection-main/Data-Collection-main/Data-CSV/crudo_V1/raw-emoji-set/EmojisIra\"\n",
    "\n",
    "# Leer el archivo asumiendo que est√° separado por comas\n",
    "df = pd.read_csv(archivo, delimiter=\",\")  # Prueba con delimiter=\",\" si es un archivo CSV est√°ndar\n",
    "\n",
    "# Mostrar una muestra aleatoria de 5 filas\n",
    "print(df.sample(5))\n",
    "\n",
    "\n",
    "\n",
    "# Extraer una muestra aleatoria de 1000 filas (si el archivo tiene m√°s de 1000 filas)\n",
    "df_muestra = df.sample(n=1000, random_state=42) if len(df) >= 1000 else df\n",
    "\n",
    "# Mostrar una muestra del dataset extra√≠do\n",
    "print(\"Muestra de 1000 comentarios:\")\n",
    "print(df_muestra.head())\n",
    "\n",
    "# Mostrar el tama√±o del archivo original\n",
    "print(f\"El dataset original tiene {len(df)} filas.\")\n",
    "\n",
    "# Guardar la muestra en un nuevo archivo CSV\n",
    "df_muestra.to_csv(\"EmojisIra_muestra.csv\", index=False)\n",
    "print(\"Se ha guardado la muestra en 'EmojisIra_muestra.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrajo muestra aleatoria del archivo EmojisIra, se trajo 1000 de 21.968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id                 created_at       username  \\\n",
      "11725  1357938335113740288  2021-02-06 06:25:03+00:00  Usuario210021   \n",
      "20737  1562587310436192256  2022-08-24 23:47:00+00:00      Jplazolah   \n",
      "7611   1346504673419796485  2021-01-05 17:11:45+00:00     ChacLesbia   \n",
      "26215  1561202609779871744  2022-08-21 04:04:42+00:00     marferr_17   \n",
      "7060   1352395222257434625  2021-01-21 23:18:41+00:00       icorroea   \n",
      "\n",
      "                                                   tweet  \n",
      "11725          @fabianys03 Yo tambi√©n quero ser gruesaüò≠üòñ  \n",
      "20737  Que clase la del maestro @lukamodric10 üò± https...  \n",
      "7611       Si...que est√°n locosüò± https://t.co/WfMQcUIKQC  \n",
      "26215    Ser insegura y estar enamorada es un infierno üòñ  \n",
      "7060   @CABLENOTICIAS Toca investigar quien es el pro...  \n",
      "Muestra de 1000 comentarios:\n",
      "                        id                 created_at        username  \\\n",
      "8158   1366906450245730310  2021-03-03 00:21:08+00:00        DuvanFe_   \n",
      "17935  1562619077398450177  2022-08-25 01:53:14+00:00  AraceliMareco7   \n",
      "23430  1560365920232636416  2022-08-18 20:40:00+00:00   vanguardiacom   \n",
      "26129  1561437729728102400  2022-08-21 19:38:59+00:00      SabogalS02   \n",
      "5453   1376731487723270153  2021-03-30 03:02:19+00:00  Sofiarhenals17   \n",
      "\n",
      "                                                   tweet  \n",
      "8158                   Esta semana empezo por la mitad.üò®  \n",
      "17935  Estoy entre la buena y la mala con todo estoüòñ ...  \n",
      "23430  Un padre y su hijo pescaban en la costa de Mai...  \n",
      "26129                         Como que as√≠ no se baila üòñ  \n",
      "5453      El ferxxoooo vio mi historia de Instagram üòçüòçüòçüò±  \n",
      "El dataset original tiene 26692 filas.\n",
      "Se ha guardado la muestra en 'EmojisMiedo_muestra.csv'.\n"
     ]
    }
   ],
   "source": [
    "archivo=\"C:/Users/edili/Downloads/Data-Collection-main/Data-Collection-main/Data-CSV/crudo_V1/raw-emoji-set/EmojisMiedo\"\n",
    "\n",
    "# Leer el archivo asumiendo que est√° separado por comas\n",
    "df = pd.read_csv(archivo, delimiter=\",\")  # Prueba con delimiter=\",\" si es un archivo CSV est√°ndar\n",
    "\n",
    "# Mostrar una muestra aleatoria de 5 filas\n",
    "print(df.sample(5))\n",
    "\n",
    "\n",
    "\n",
    "# Extraer una muestra aleatoria de 1000 filas (si el archivo tiene m√°s de 1000 filas)\n",
    "df_muestra = df.sample(n=1000, random_state=42) if len(df) >= 1000 else df\n",
    "\n",
    "# Mostrar una muestra del dataset extra√≠do\n",
    "print(\"Muestra de 1000 comentarios:\")\n",
    "print(df_muestra.head())\n",
    "\n",
    "# Mostrar el tama√±o del archivo original\n",
    "print(f\"El dataset original tiene {len(df)} filas.\")\n",
    "\n",
    "# Guardar la muestra en un nuevo archivo CSV\n",
    "df_muestra.to_csv(\"EmojisMiedo_muestra.csv\", index=False)\n",
    "print(\"Se ha guardado la muestra en 'EmojisMiedo_muestra.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrajo muestra aleatoria del archivo EmojisMiedo, se trajo 1000 de 26.692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id                 created_at         username  \\\n",
      "3673   1358095757983838209  2021-02-06 16:50:35+00:00    gloriamelania   \n",
      "3488   1378697830416670722  2021-04-04 13:15:52+00:00   LuisEnrique_30   \n",
      "3794   1397979547145015297  2021-05-27 18:14:31+00:00  Roselis02692873   \n",
      "12727  1560439259861061634  2022-08-19 01:31:25+00:00     QHuboMedallo   \n",
      "16586  1561557489329512448  2022-08-22 03:34:52+00:00         Fobos2_3   \n",
      "\n",
      "                                                   tweet  \n",
      "3673   @Montezbent Oh, es por esa carretera que se va...  \n",
      "3488                Por lo menis alguien so√±o conmigo üòØü•∫  \n",
      "3794   @Mongua25 Demencia senil se llama eso!! No sab...  \n",
      "12727  #Deportes Pese a que antes se les ve√≠a muy uni...  \n",
      "16586  Que ladilla no poder dormir si no te arropas y...  \n",
      "Muestra de 1000 comentarios:\n",
      "                        id                 created_at        username  \\\n",
      "4894   1348446594568507400  2021-01-11 01:48:15+00:00  lalolitalinda1   \n",
      "10468  1562814816338599938  2022-08-25 14:51:02+00:00    rigogarciaTV   \n",
      "23128  1560885198283313152  2022-08-20 07:03:25+00:00         Jeiti12   \n",
      "11816  1561428344872189953  2022-08-21 19:01:42+00:00  Sindygonzalezv   \n",
      "22553  1561503578262478850  2022-08-22 00:00:39+00:00      CaroSoci4l   \n",
      "\n",
      "                                                   tweet  \n",
      "4894   @critico2_ HaaaajaaaajajaüòÇüòÉüòÇüòÅ..\\nA mala leche....  \n",
      "10468  Hoy active la campanita de @aljorp18 est√°s enf...  \n",
      "23128                   Que ganas de salir con Tigo üòµ‚Äçüí´ü•¥  \n",
      "11816  Yo con dos copas de vino ya quiero incendiar l...  \n",
      "22553  @adrescala @lafm Ese informe parece hecho para...  \n",
      "El dataset original tiene 23850 filas.\n",
      "Se ha guardado la muestra en 'EmojisSorpresa_muestra.csv'.\n"
     ]
    }
   ],
   "source": [
    "archivo=\"C:/Users/edili/Downloads/Data-Collection-main/Data-Collection-main/Data-CSV/crudo_V1/raw-emoji-set/EmojisSorpresa\"\n",
    "\n",
    "# Leer el archivo asumiendo que est√° separado por comas\n",
    "df = pd.read_csv(archivo, delimiter=\",\")  # Prueba con delimiter=\",\" si es un archivo CSV est√°ndar\n",
    "\n",
    "# Mostrar una muestra aleatoria de 5 filas\n",
    "print(df.sample(5))\n",
    "\n",
    "\n",
    "\n",
    "# Extraer una muestra aleatoria de 1000 filas (si el archivo tiene m√°s de 1000 filas)\n",
    "df_muestra = df.sample(n=2000, random_state=42) if len(df) >= 2000 else df\n",
    "\n",
    "# Mostrar una muestra del dataset extra√≠do\n",
    "print(\"Muestra de 2000 comentarios:\")\n",
    "print(df_muestra.head())\n",
    "\n",
    "# Mostrar el tama√±o del archivo original\n",
    "print(f\"El dataset original tiene {len(df)} filas.\")\n",
    "\n",
    "# Guardar la muestra en un nuevo archivo CSV\n",
    "df_muestra.to_csv(\"EmojisSorpresa_muestra.csv\", index=False)\n",
    "print(\"Se ha guardado la muestra en 'EmojisSorpresa_muestra.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrajo muestra aleatoria del archivo EmojisSorpresa, se trajo 1000 de 23.850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de emojis por sentimiento\n",
    "emojis_por_sentimiento = {\n",
    "    'alegria': ['üòä', 'üòÇ', 'üòÅ', 'üòÑ', 'üòÉ', 'üòÜ', 'üòÖ', 'ü§£', 'ü•∞', 'üòç', 'üòò', 'üòé', 'üòá', 'üòå', '‚ò∫Ô∏è', 'üôÇ'],\n",
    "    'asco': ['ü§¢', 'ü§Æ', 'üò∑'],\n",
    "    'ira': ['üò°', 'üò†', 'ü§¨', 'üò§', 'üòæ', 'üëø', 'üí¢'],\n",
    "    'miedo': ['üò®', 'üò∞', 'üò±', 'üòß', 'üòñ'],\n",
    "    'sorpresa': ['üò≤', 'üòØ', 'üò≥', 'ü§Ø', 'üòÆ'],\n",
    "    'tristeza': ['üò¢', 'üò≠', 'üòû', 'üòî', 'üòü', 'üòì', 'üò•', 'üò©', 'üòø']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos desde el archivo CSV\n",
    "ruta_archivo = \"EmojisAlegria_muestra.csv\"  # Aseg√∫rate de tener la ruta correcta\n",
    "df = pd.read_csv(ruta_archivo)\n",
    "\n",
    "# Mostrar los primeros registros antes del preprocesamiento\n",
    "print(\"Datos antes del preprocesamiento:\")\n",
    "print(df.head())\n",
    "\n",
    "# Funci√≥n para limpiar los comentarios\n",
    "def limpiar_comentario(texto):\n",
    "    texto = texto.lower()  # Convertir a min√∫sculas\n",
    "    texto = re.sub(r'@\\w+', '', texto)  # Eliminar menciones\n",
    "    texto = re.sub(r'http\\S+', '', texto)  # Eliminar enlaces\n",
    "    texto = re.sub(r'[^a-zA-Z√°√©√≠√≥√∫√±√º√Å√â√ç√ì√ö√ë√ú\\s\\.,;!?ü§óüòÇüòçüòäüòÖü§£üò≠üò°üò†üò§üòìüòîüò¢]', '', texto)  # Eliminar caracteres especiales, conservar emojis comunes\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()  # Eliminar espacios extra\n",
    "    return texto\n",
    "\n",
    "# Aplicar la funci√≥n de limpieza a la columna de comentarios\n",
    "df['comentario'] = df['tweet'].apply(limpiar_comentario)\n",
    "\n",
    "# Asignar la etiqueta de \"Alegr√≠a\" a cada comentario\n",
    "df['sentimiento'] = 'Alegr√≠a'\n",
    "\n",
    "# Eliminar la columna original 'tweet' si ya no es necesaria\n",
    "df = df[['comentario', 'sentimiento']]\n",
    "\n",
    "# Mostrar los primeros registros despu√©s del preprocesamiento\n",
    "print(\"Datos despu√©s del preprocesamiento:\")\n",
    "print(df.head())\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "df.to_csv(\"EmojisAlegria_procesado.csv\", index=False)\n",
    "print(\"Datos procesados guardados en 'EmojisAlegria_procesado.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando archivo: EmojisMuestras/EmojisAlegria_muestra.csv con sentimiento: Muestras/alegria\n",
      "Muestra de comentarios procesados del archivo EmojisMuestras/EmojisAlegria_muestra.csv:\n",
      "                                               tweet       sentimiento\n",
      "0  la pelua tiene cara de consentida y caprichosa...  Muestras/alegria\n",
      "1               felices estamos! comimos empanadas üòÅ  Muestras/alegria\n",
      "2                                        muy bueno üòÑ  Muestras/alegria\n",
      "3                 en ese momento cell, se derriti√≥.üòç  Muestras/alegria\n",
      "4  yo nunca lo he fumado! de echo yo fumo muy de ...  Muestras/alegria\n",
      "\n",
      "Procesando archivo: EmojisMuestras/EmojisAsco_muestra.csv con sentimiento: Muestras/asco\n",
      "Muestra de comentarios procesados del archivo EmojisMuestras/EmojisAsco_muestra.csv:\n",
      "                                               tweet    sentimiento\n",
      "0      ese juan david se come un vomito ü§Æ ü§¢ü§¢ü§Æü§Æüò°üò°üò°üò°üò°üò°  Muestras/asco\n",
      "1  se nota que eres una persona envidiosa ü§¢ no di...  Muestras/asco\n",
      "2  so√±e q me com√≠a un paquete entero de chocolina...  Muestras/asco\n",
      "3  verdad que cuando uno no tiene sed el agua sab...  Muestras/asco\n",
      "4  habr√° alguien que no elimine esa horrible cost...  Muestras/asco\n",
      "\n",
      "Procesando archivo: EmojisMuestras/EmojisIra_muestra.csv con sentimiento: Muestras/ira\n",
      "Muestra de comentarios procesados del archivo EmojisMuestras/EmojisIra_muestra.csv:\n",
      "                                               tweet   sentimiento\n",
      "0                                      qu√© tal???üò°üò°üò°  Muestras/ira\n",
      "1  quue ganas las que me dan de afinarles ese mal...  Muestras/ira\n",
      "2  alcalde payaso!!! jugando con la opini√≥n p√∫bli...  Muestras/ira\n",
      "3  todo es un negocio redondo, invaden para vende...  Muestras/ira\n",
      "4  y ni hablar de la situaci√≥n sanitaria por el c...  Muestras/ira\n",
      "\n",
      "Procesando archivo: EmojisMuestras/EmojisMiedo_muestra.csv con sentimiento: Muestras/miedo\n",
      "Muestra de comentarios procesados del archivo EmojisMuestras/EmojisMiedo_muestra.csv:\n",
      "                                               tweet     sentimiento\n",
      "0                  esta semana empezo por la mitad.üò®  Muestras/miedo\n",
      "1      estoy entre la buena y la mala con todo estoüòñ  Muestras/miedo\n",
      "2  un padre y su hijo pescaban en la costa de mai...  Muestras/miedo\n",
      "3                         como que as√≠ no se baila üòñ  Muestras/miedo\n",
      "4     el ferxxoooo vio mi historia de instagram üòçüòçüòçüò±  Muestras/miedo\n",
      "\n",
      "Procesando archivo: EmojisMuestras/EmojisSorpresa_muestra.csv con sentimiento: Muestras/sorpresa\n",
      "Muestra de comentarios procesados del archivo EmojisMuestras/EmojisSorpresa_muestra.csv:\n",
      "                                               tweet        sentimiento\n",
      "0             haaaajaaaajajaüòÇüòÉüòÇüòÅ.. a mala leche..üò≤üò≤üò≤  Muestras/sorpresa\n",
      "1  hoy active la campanita de est√°s enfermo con e...  Muestras/sorpresa\n",
      "2                        que ganas de salir con tigo  Muestras/sorpresa\n",
      "3  yo con dos copas de vino ya quiero incendiar l...  Muestras/sorpresa\n",
      "4  ese informe parece hecho para limpiar a los ba...  Muestras/sorpresa\n",
      "\n",
      "Procesando archivo: EmojisMuestras/EmojisTristeza_muestra.csv con sentimiento: Muestras/tristeza\n",
      "Muestra de comentarios procesados del archivo EmojisMuestras/EmojisTristeza_muestra.csv:\n",
      "                                               tweet        sentimiento\n",
      "0                               aaahh que triste bro  Muestras/tristeza\n",
      "1  s√°bado de precarnaval y yo acostadaüò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠...  Muestras/tristeza\n",
      "2              la triste historia de una enga√±ada üòüüò≠  Muestras/tristeza\n",
      "3                 odio tomarme fotos para documentos  Muestras/tristeza\n",
      "4  mi d√≠a iba perfecto por que nos haces esto??? ...  Muestras/tristeza\n",
      "\n",
      "Se han combinado todos los archivos y guardado en 'Emojis_clean.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Diccionario de emojis por sentimiento\n",
    "emojis_por_sentimiento = {\n",
    "    'alegria': ['üòä', 'üòÇ', 'üòÅ', 'üòÑ', 'üòÉ', 'üòÜ', 'üòÖ', 'ü§£', 'ü•∞', 'üòç', 'üòò', 'üòé', 'üòá', 'üòå', '‚ò∫Ô∏è', 'üôÇ'],\n",
    "    'asco': ['ü§¢', 'ü§Æ', 'üò∑'],\n",
    "    'ira': ['üò°', 'üò†', 'ü§¨', 'üò§', 'üòæ', 'üëø', 'üí¢'],\n",
    "    'miedo': ['üò®', 'üò∞', 'üò±', 'üòß', 'üòñ'],\n",
    "    'sorpresa': ['üò≤', 'üòØ', 'üò≥', 'ü§Ø', 'üòÆ'],\n",
    "    'tristeza': ['üò¢', 'üò≠', 'üòû', 'üòî', 'üòü', 'üòì', 'üò•', 'üò©', 'üòø']\n",
    "}\n",
    "\n",
    "# Crear una cadena con todos los emojis del diccionario\n",
    "todos_los_emojis = ''.join([emoji for lista in emojis_por_sentimiento.values() for emoji in lista])\n",
    "\n",
    "# Funci√≥n de limpieza de comentarios\n",
    "def limpiar_comentario(texto):\n",
    "    texto = texto.lower()  # Convertir a min√∫sculas\n",
    "    texto = re.sub(r'@\\w+', '', texto)  # Eliminar menciones\n",
    "    texto = re.sub(r'http\\S+', '', texto)  # Eliminar enlaces\n",
    "    texto = re.sub(fr'[^a-zA-Z√°√©√≠√≥√∫√±√º√Å√â√ç√ì√ö√ë√ú\\s\\.,;!?{re.escape(todos_los_emojis)}]', '', texto)  # Conservar texto y emojis relevantes\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()  # Eliminar espacios extra\n",
    "    return texto\n",
    "\n",
    "# Lista de archivos CSV de muestra por sentimiento\n",
    "archivos = [\n",
    "    \"EmojisMuestras/EmojisAlegria_muestra.csv\",\n",
    "    \"EmojisMuestras/EmojisAsco_muestra.csv\",\n",
    "    \"EmojisMuestras/EmojisIra_muestra.csv\",\n",
    "    \"EmojisMuestras/EmojisMiedo_muestra.csv\",\n",
    "    \"EmojisMuestras/EmojisSorpresa_muestra.csv\",\n",
    "    \"EmojisMuestras/EmojisTristeza_muestra.csv\"\n",
    "]\n",
    "\n",
    "# Crear una lista vac√≠a para almacenar los DataFrames procesados\n",
    "dataframes = []\n",
    "\n",
    "# Procesar cada archivo\n",
    "for archivo in archivos:\n",
    "    # Extraer el sentimiento del nombre del archivo\n",
    "    sentimiento = archivo.split('_')[0].replace('Emojis', '')\n",
    "    sentimiento = sentimiento.capitalize()\n",
    "    \n",
    "    print(f\"\\nProcesando archivo: {archivo} con sentimiento: {sentimiento}\")\n",
    "    \n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(archivo)\n",
    "    \n",
    "    # Aplicar la limpieza al texto de los comentarios\n",
    "    df['tweet'] = df['tweet'].apply(limpiar_comentario)\n",
    "    \n",
    "    # Asignar la etiqueta de sentimiento\n",
    "    df['sentimiento'] = sentimiento\n",
    "    \n",
    "    # Filtrar solo las columnas 'tweet' y 'sentimiento'\n",
    "    df = df[['tweet', 'sentimiento']]\n",
    "    \n",
    "    # Mostrar una muestra de los comentarios procesados\n",
    "    print(f\"Muestra de comentarios procesados del archivo {archivo}:\")\n",
    "    print(df.head(5))  # Mostrar las primeras 5 filas\n",
    "    \n",
    "    # Agregar el DataFrame a la lista\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combinar todos los DataFrames en uno solo\n",
    "df_completo = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame combinado en un nuevo archivo CSV\n",
    "df_completo.to_csv(\"Emojis_clean_Final.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSe han combinado todos los archivos y guardado en 'Emojis_clean.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  tweet sentimiento\n",
      "2223                                       val√≠ verga.ü§¨         ira\n",
      "5919  cuando le agarras el gustico ya no hay vuelta ...    tristeza\n",
      "74    la gente que pelea por las redes estar√° clara ...     alegria\n",
      "2101                                exacto... poco de üò†         ira\n",
      "5005  üò≠üò≠üò≠üò≠üò≠üò≠üò¢üò¢üò¢üò¢los necesitamos en brisas del lago. ...    tristeza\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo 'Emojis_clean.csv'\n",
    "df = pd.read_csv(\"Emojis_clean_Final.csv\")\n",
    "\n",
    "# Eliminar 'Muestras/' de la columna 'sentimiento'\n",
    "df['sentimiento'] = df['sentimiento'].str.replace('Muestras/', '')\n",
    "\n",
    "# Mostrar una muestra de los datos para verificar\n",
    "print(df.sample(5))\n",
    "\n",
    "# Guardar el DataFrame corregido en un nuevo archivo CSV\n",
    "df.to_csv(\"Emojis_clean_corregido.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 comment    label     score\n",
      "3197   si me intentan recordar cualquier cosa que pas...  sadness  0.864857\n",
      "22295  el hecho: un lider de la dictadura venezolana ...    anger  0.718086\n",
      "2543   y sean cual sean los resultados, de ganar los ...    anger  0.712063\n",
      "8268   no solo fue uno de los grandes, fuiste el mas ...      joy  0.697996\n",
      "21243  leyes ni tribunales nacionales ni obligadas a ...   others  0.612450\n",
      "Muestra de 2000 comentarios:\n",
      "                                                 comment    label     score\n",
      "12965  ahora pues todos salimos a defender a la delin...    anger  0.786757\n",
      "15844  efectivamente, el gobierno colombiano en su di...   others  0.503853\n",
      "15518                 que chiste la politica venezolana.    anger  0.695433\n",
      "18533  una pregunta, preguntada, hasta cuando se le v...    anger  0.792717\n",
      "8803   en las manos de los votantes, esta la oportuni...  sadness  0.791032\n",
      "El dataset original tiene 22558 filas.\n",
      "Se ha guardado la muestra en 'PoliticaMuestra.csv'.\n"
     ]
    }
   ],
   "source": [
    "archivo=\"C:/Users/edili/Downloads/Data-Collection-main/Data-Collection-main/Data-CSV/limpio-venezolano_V1/Politica\"\n",
    "\n",
    "# Leer el archivo asumiendo que est√° separado por comas\n",
    "df = pd.read_csv(archivo, delimiter=\";\")  # Prueba con delimiter=\",\" si es un archivo CSV est√°ndar\n",
    "\n",
    "# Mostrar una muestra aleatoria de 5 filas\n",
    "print(df.sample(5))\n",
    "\n",
    "\n",
    "\n",
    "# Extraer una muestra aleatoria de 1000 filas (si el archivo tiene m√°s de 1000 filas)\n",
    "df_muestra = df.sample(n=2000, random_state=42) if len(df) >= 2000 else df\n",
    "\n",
    "# Mostrar una muestra del dataset extra√≠do\n",
    "print(\"Muestra de 2000 comentarios:\")\n",
    "print(df_muestra.head())\n",
    "\n",
    "# Mostrar el tama√±o del archivo original\n",
    "print(f\"El dataset original tiene {len(df)} filas.\")\n",
    "\n",
    "# Guardar la muestra en un nuevo archivo CSV\n",
    "df_muestra.to_csv(\"PoliticaMuestra.csv\", index=False)\n",
    "print(\"Se ha guardado la muestra en 'PoliticaMuestra.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extrayendo datos de migraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha guardado el dataset preprocesado en 'MigracionPreprocesado.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "archivo = \"MigracionMuestraFiltrada.csv\"\n",
    "df = pd.read_csv(archivo, delimiter=\",\", encoding='utf-8')\n",
    "\n",
    "# Funci√≥n de limpieza del texto\n",
    "def limpiar_texto(texto):\n",
    "    texto = texto.lower()  # Convertir a min√∫sculas\n",
    "    texto = re.sub(r'#[^\\s]+', '', texto)  # Eliminar hashtags\n",
    "    texto = re.sub(r'http\\S+', '', texto)  # Eliminar URLs\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)  # Eliminar signos de puntuaci√≥n\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()  # Eliminar espacios extra\n",
    "    return texto\n",
    "\n",
    "# Aplicar la limpieza al texto de los comentarios\n",
    "df['comment'] = df['comment'].apply(limpiar_texto)\n",
    "\n",
    "# Renombrar la columna 'label' a 'sentimiento' y a√±adir el tema 'migracion'\n",
    "df = df.rename(columns={'label': 'sentimiento'})\n",
    "df['tema'] = 'migracion'\n",
    "\n",
    "# Eliminar la columna 'score' ya que no es necesaria\n",
    "df = df.drop(columns=['score'])\n",
    "\n",
    "# Guardar el dataset preprocesado\n",
    "df.to_csv(\"MigracionPreprocesado.csv\", index=False, encoding='utf-8')\n",
    "print(\"Se ha guardado el dataset preprocesado en 'MigracionPreprocesado.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset tiene 4 sentimientos √∫nicos:\n",
      "['anger' 'sadness' 'joy' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cargar el dataset preprocesado\n",
    "archivo = \"PoliticaPreprocesado.csv\"\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Contar la cantidad de sentimientos √∫nicos y listarlos\n",
    "sentimientos_unicos = df['sentimiento'].unique()\n",
    "cantidad_sentimientos = len(sentimientos_unicos)\n",
    "\n",
    "print(f\"El dataset tiene {cantidad_sentimientos} sentimientos √∫nicos:\")\n",
    "print(sentimientos_unicos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de comentarios por cada sentimiento:\n",
      "sentimiento\n",
      "anger       1431\n",
      "sadness      364\n",
      "joy          203\n",
      "surprise       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cargar el dataset\n",
    "archivo = \"PoliticaPreprocesado.csv\"\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Contar los comentarios por cada sentimiento\n",
    "conteo_sentimientos = df['sentimiento'].value_counts()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Cantidad de comentarios por cada sentimiento:\")\n",
    "print(conteo_sentimientos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra de 2000 comentarios (sin 'others'):\n",
      "                                                 comment    label     score\n",
      "2048   los ninos en colombia mueren por desnutricion ...  sadness  0.931262\n",
      "5871   deja de mentir, de verdad ya es enfermo cuenta...    anger  0.755786\n",
      "5817   es cierto, pero tambien hay que prestarle aten...  sadness  0.899468\n",
      "8055   un grupo de migrantes compartio en redes socia...  sadness  0.529940\n",
      "15988  la migracion colombiana hacia venezuela y pais...  sadness  0.420284\n",
      "El dataset filtrado tiene 8072 filas.\n",
      "Se ha guardado la muestra filtrada en 'MigracionMuestraFiltrada.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "archivo = \"C:/Users/edili/Downloads/Data-Collection-main/Data-Collection-main/Data-CSV/limpio-venezolano_V1/Migracion\"\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv(archivo, delimiter=\";\")\n",
    "\n",
    "# Filtrar los comentarios que no tengan el sentimiento \"others\"\n",
    "df_filtrado = df[df['label'] != 'others']\n",
    "\n",
    "# Extraer una muestra aleatoria de 2000 filas (si el dataset filtrado tiene m√°s de 2000 filas)\n",
    "df_muestra = df_filtrado.sample(n=2000, random_state=42) if len(df_filtrado) >= 2000 else df_filtrado\n",
    "\n",
    "# Mostrar una muestra del dataset filtrado\n",
    "print(\"Muestra de 2000 comentarios (sin 'others'):\")\n",
    "print(df_muestra.head())\n",
    "\n",
    "# Mostrar el tama√±o del dataset filtrado\n",
    "print(f\"El dataset filtrado tiene {len(df_filtrado)} filas.\")\n",
    "\n",
    "# Guardar la muestra filtrada en un nuevo archivo CSV\n",
    "df_muestra.to_csv(\"MigracionMuestraFiltrada.csv\", index=False)\n",
    "print(\"Se ha guardado la muestra filtrada en 'MigracionMuestraFiltrada.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayendo la mustra sin tomar encuenta Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han guardado los archivos con los sentimientos en espa√±ol.\n",
      "Se ha guardado el dataset combinado en 'DatasetCombinadoPM.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cargar el archivo preprocesado de pol√≠tica\n",
    "archivo_politica = \"PoliticaPreprocesado.csv\"\n",
    "df_politica = pd.read_csv(archivo_politica)\n",
    "\n",
    "# Cargar el archivo preprocesado de migraci√≥n\n",
    "archivo_migracion = \"MigracionPreprocesado.csv\"\n",
    "df_migracion = pd.read_csv(archivo_migracion)\n",
    "\n",
    "# Crear un diccionario para traducir los sentimientos\n",
    "traduccion_sentimientos = {\n",
    "    'anger': 'ira',\n",
    "    'sadness': 'tristeza',\n",
    "    'joy': 'alegria',\n",
    "    'surprise': 'sorpresa'\n",
    "}\n",
    "\n",
    "# Reemplazar los nombres de los sentimientos en ambos datasets\n",
    "df_politica['sentimiento'] = df_politica['sentimiento'].map(traduccion_sentimientos)\n",
    "df_migracion['sentimiento'] = df_migracion['sentimiento'].map(traduccion_sentimientos)\n",
    "\n",
    "# Guardar los datasets actualizados\n",
    "df_politica.to_csv(\"PoliticaMuestraEsp.csv\", index=False)\n",
    "df_migracion.to_csv(\"MigracionMuestraEsp.csv\", index=False)\n",
    "\n",
    "print(\"Se han guardado los archivos con los sentimientos en espa√±ol.\")\n",
    "\n",
    "# Unir los datasets de pol√≠tica y migraci√≥n\n",
    "df_combinado = pd.concat([df_politica, df_migracion], ignore_index=True)\n",
    "\n",
    "# Guardar el dataset combinado\n",
    "df_combinado.to_csv(\"DatasetCombinadoPM.csv\", index=False)\n",
    "print(\"Se ha guardado el dataset combinado en 'DatasetCombinadoPM.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset preprocesado:\n",
      "                                             comment  sentimiento      tema  \\\n",
      "0  la politica venezolana paso de ser un chiste a...          2.0  politica   \n",
      "1  lo que le hicieron a raul isaias baduel quedar...          2.0  politica   \n",
      "2  respeten que gente de poca mente superenlo no ...          2.0  politica   \n",
      "3  lo dice un dinosaurio de la politica venezolan...          2.0  politica   \n",
      "4  que insistencia la de caramelo de colaborar co...          2.0  politica   \n",
      "\n",
      "   politica  migracion  \n",
      "0         1          0  \n",
      "1         1          0  \n",
      "2         1          0  \n",
      "3         1          0  \n",
      "4         1          0  \n",
      "El dataset preprocesado se ha guardado como 'DatasetCombinadoPM_Corregido.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Leer el dataset\n",
    "df = pd.read_csv(\"DatasetCombinadoPM.csv\")  # Cambia 'tu_dataset.csv' por el nombre de tu archivo\n",
    "\n",
    "# Eliminar espacios adicionales en las columnas 'sentimiento' y 'tema'\n",
    "df['sentimiento'] = df['sentimiento'].str.strip()\n",
    "df['tema'] = df['tema'].str.strip()\n",
    "\n",
    "# Definir el mapeo de las etiquetas de 'sentimiento' y 'tema'\n",
    "sentimiento_map = {'alegria': 0, 'asco': 1, 'ira': 2, 'miedo': 3, 'sorpresa': 4, 'tristeza': 5}\n",
    "\n",
    "# Aplicar el mapeo de sentimientos\n",
    "df['sentimiento'] = df['sentimiento'].map(sentimiento_map)\n",
    "\n",
    "# Crear columnas binarias para los temas\n",
    "df['politica'] = df['tema'].apply(lambda x: 1 if x == 'politica' else 0)\n",
    "df['migracion'] = df['tema'].apply(lambda x: 1 if x == 'migracion' else 0)\n",
    "\n",
    "# Verificar los resultados\n",
    "print(\"Primeras filas del dataset preprocesado:\")\n",
    "print(df.head())\n",
    "\n",
    "# Guardar el dataset preprocesado en un nuevo archivo CSV\n",
    "df.to_csv(\"DatasetCombinadoPM_Corregido.csv\", index=False)\n",
    "print(\"El dataset preprocesado se ha guardado como 'DatasetCombinadoPM_Corregido.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset final se ha guardado como 'DatasetCombinadoPM_Final.csv'\n"
     ]
    }
   ],
   "source": [
    "# Eliminar la columna 'tema'\n",
    "df.drop(columns=['tema'], inplace=True)\n",
    "\n",
    "# Guardar el dataset final\n",
    "df.to_csv(\"DatasetCombinadoPM_Final.csv\", index=False)\n",
    "print(\"El dataset final se ha guardado como 'DatasetCombinadoPM_Final.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentarios duplicados:\n",
      "                                               comment sentimiento       tema\n",
      "0    Es incre√≠ble ver c√≥mo Maduro sigue gobernando ...       Miedo  migraci√≥n\n",
      "1    El futuro de Venezuela parece incierto. Cada v...         Ira  migraci√≥n\n",
      "2    La tristeza es ver c√≥mo los j√≥venes venezolano...    Sorpresa  migraci√≥n\n",
      "3    Maduro ha hecho que la situaci√≥n empeore cada ...       Miedo  migraci√≥n\n",
      "4    Mar√≠a Corina Machado tiene un plan claro para ...    Sorpresa  migraci√≥n\n",
      "..                                                 ...         ...        ...\n",
      "995  El futuro de Venezuela parece incierto. Cada v...         Ira    ninguno\n",
      "996  Mar√≠a Corina Machado est√° luchando por un camb...    Sorpresa  migraci√≥n\n",
      "997  La gente se est√° cansando de la situaci√≥n, el ...       Miedo   pol√≠tica\n",
      "998  Mar√≠a Corina Machado est√° dispuesta a cambiar ...    Sorpresa   pol√≠tica\n",
      "999  La gente se est√° cansando de la situaci√≥n, el ...    Tristeza  migraci√≥n\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset desde el archivo CSV\n",
    "df = pd.read_csv('C:/Users/edili/Downloads/Exodus/dataset_venezuelan_comments.csv')\n",
    "\n",
    "# Verificar los comentarios duplicados\n",
    "duplicados = df[df.duplicated(subset='comment', keep=False)]\n",
    "\n",
    "# Mostrar los comentarios duplicados\n",
    "print(\"Comentarios duplicados:\")\n",
    "print(duplicados)\n",
    "\n",
    "# Opcional: guardar los comentarios duplicados en un nuevo archivo CSV\n",
    "duplicados.to_csv('comentarios_duplicados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes de eliminar duplicados: 1000 comentarios.\n",
      "Despu√©s de eliminar duplicados: 10 comentarios.\n",
      "El dataset sin duplicados se ha guardado como 'dataset_sin_duplicados.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset desde el archivo CSV\n",
    "df = pd.read_csv('C:/Users/edili/Downloads/Exodus/dataset_venezuelan_comments.csv')\n",
    "\n",
    "# Eliminar los comentarios duplicados, manteniendo solo la primera aparici√≥n\n",
    "df_sin_duplicados = df.drop_duplicates(subset='comment', keep='first')\n",
    "\n",
    "# Verificar que se eliminaron los duplicados\n",
    "print(f\"Antes de eliminar duplicados: {len(df)} comentarios.\")\n",
    "print(f\"Despu√©s de eliminar duplicados: {len(df_sin_duplicados)} comentarios.\")\n",
    "\n",
    "# Guardar el dataset sin duplicados en un nuevo archivo CSV\n",
    "df_sin_duplicados.to_csv('dataset_sin_duplicados.csv', index=False)\n",
    "\n",
    "print(\"El dataset sin duplicados se ha guardado como 'dataset_sin_duplicados.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet sentimiento\n",
      "0  la pelua tiene cara de consentida y caprichosa...     alegria\n",
      "1               felices estamos! comimos empanadas üòÅ     alegria\n",
      "2                                        muy bueno üòÑ     alegria\n",
      "3                 en ese momento cell, se derriti√≥.üòç     alegria\n",
      "4  yo nunca lo he fumado! de echo yo fumo muy de ...     alegria\n",
      "                                               tweet sentimiento     tema\n",
      "0  la pelua tiene cara de consentida y caprichosa...     alegria  ninguno\n",
      "1               felices estamos! comimos empanadas üòÅ     alegria  ninguno\n",
      "2                                        muy bueno üòÑ     alegria  ninguno\n",
      "3                 en ese momento cell, se derriti√≥.üòç     alegria  ninguno\n",
      "4  yo nunca lo he fumado! de echo yo fumo muy de ...     alegria  ninguno\n",
      "El dataset con tema 'ninguno' ha sido guardado como 'dataset_con_tema_ninguno.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edili\\AppData\\Local\\Temp\\ipykernel_22376\\1580435019.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_200['tema'] = 'ninguno'\n",
      "C:\\Users\\edili\\AppData\\Local\\Temp\\ipykernel_22376\\1580435019.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_200['tema'] = 'ninguno'\n",
      "C:\\Users\\edili\\AppData\\Local\\Temp\\ipykernel_22376\\1580435019.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_200['tema'] = 'ninguno'\n",
      "C:\\Users\\edili\\AppData\\Local\\Temp\\ipykernel_22376\\1580435019.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_200['tema'] = 'ninguno'\n",
      "C:\\Users\\edili\\AppData\\Local\\Temp\\ipykernel_22376\\1580435019.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_200['tema'] = 'ninguno'\n",
      "C:\\Users\\edili\\AppData\\Local\\Temp\\ipykernel_22376\\1580435019.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_200['tema'] = 'ninguno'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset con solo los sentimientos (supongo que se llama 'sentimientos_dataset.csv')\n",
    "df_sentimientos = pd.read_csv('Emojis_clean_corregido.csv')  # Cambia la ruta si es necesario\n",
    "\n",
    "# Verificar la estructura del dataset original\n",
    "print(df_sentimientos.head())\n",
    "\n",
    "# Filtrar 200 comentarios de cada sentimiento\n",
    "sentimientos_unicos = df_sentimientos['sentimiento'].unique()\n",
    "\n",
    "# Crear una lista para almacenar los comentarios etiquetados\n",
    "comentarios_etiquetados = []\n",
    "\n",
    "# Iterar sobre cada sentimiento y seleccionar 200 comentarios\n",
    "for sentimiento in sentimientos_unicos:\n",
    "    df_sentimiento = df_sentimientos[df_sentimientos['sentimiento'] == sentimiento]\n",
    "    comentarios_200 = df_sentimiento.head(200)  # Seleccionar los primeros 200 comentarios para cada sentimiento\n",
    "    \n",
    "    # A√±adir la etiqueta \"ninguno\" en la columna 'tema'\n",
    "    comentarios_200['tema'] = 'ninguno'\n",
    "    \n",
    "    # Agregar los comentarios a la lista\n",
    "    comentarios_etiquetados.append(comentarios_200)\n",
    "\n",
    "# Concatenar todos los fragmentos de datos para obtener el dataset final\n",
    "df_etiquetado = pd.concat(comentarios_etiquetados)\n",
    "\n",
    "# Verificar que se haya etiquetado correctamente\n",
    "print(df_etiquetado.head())\n",
    "\n",
    "# Guardar el dataset etiquetado\n",
    "df_etiquetado.to_csv('dataset_con_tema_ninguno.csv', index=False)\n",
    "\n",
    "print(\"El dataset con tema 'ninguno' ha sido guardado como 'dataset_con_tema_ninguno.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/EmojisMuestras/TweetsExtraidosLimpios.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Cargar el dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/EmojisMuestras/TweetsExtraidosLimpios.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Aseg√∫rate de que el archivo est√© en la ruta correcta\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Verificar la estructura del dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\edili\\Downloads\\Exodus\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\edili\\Downloads\\Exodus\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\edili\\Downloads\\Exodus\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\edili\\Downloads\\Exodus\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\edili\\Downloads\\Exodus\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/EmojisMuestras/TweetsExtraidosLimpios.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('/EmojisMuestras/TweetsExtraidosLimpios.csv')  # Aseg√∫rate de que el archivo est√© en la ruta correcta\n",
    "\n",
    "# Verificar la estructura del dataset\n",
    "print(df.head())\n",
    "\n",
    "# Funci√≥n para preprocesar los comentarios: poner comillas, convertir a min√∫sculas y eliminar caracteres no deseados\n",
    "def preprocesar_comentarios(comment):\n",
    "    # Paso 1: Convertir el texto a min√∫sculas\n",
    "    comment = comment.lower()\n",
    "    \n",
    "    # Paso 2: Eliminar comillas dobles o simples al principio y al final (si ya las tiene)\n",
    "    comment = re.sub(r\"^['\\\"](.*)['\\\"]$\", r\"\\1\", comment)  # Elimina las comillas al inicio y fin\n",
    "    \n",
    "    # Paso 3: Eliminar caracteres no deseados, pero conservar los emojis\n",
    "    # Usamos una expresi√≥n regular para dejar solo letras, n√∫meros, espacios y emojis\n",
    "    comment = re.sub(r'[^a-zA-Z0-9\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702\\U00002705\\U0000270A\\U0000270B\\U0001F004\\U0001F0CF]', '', comment)\n",
    "    \n",
    "\n",
    "    \n",
    "    return comment\n",
    "\n",
    "# Aplicar la funci√≥n de preprocesamiento a la columna 'comment'\n",
    "df['comment'] = df['comment'].apply(preprocesar_comentarios)\n",
    "\n",
    "# Verificar el dataset despu√©s del preprocesamiento\n",
    "print(df.head())\n",
    "\n",
    "# Guardar el dataset preprocesado\n",
    "df.to_csv('dataset2.csv', index=False)\n",
    "\n",
    "print(\"El dataset preprocesado ha sido guardado como 'dataset_preprocesado.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment sentimiento      tema\n",
      "0  \"la politica venezolana paso de ser un chiste ...         ira  politica\n",
      "1  \"lo que le hicieron a raul isaias baduel queda...         ira  politica\n",
      "2  \"respeten que gente de poca mente superenlo no...         ira  politica\n",
      "3  \"lo dice un dinosaurio de la politica venezola...         ira  politica\n",
      "4  \"que insistencia la de caramelo de colaborar c...         ira  politica\n",
      "                                             comment sentimiento      tema\n",
      "0  la politica venezolana paso de ser un chiste a...         ira  politica\n",
      "1  lo que le hicieron a raul isaias baduel quedar...         ira  politica\n",
      "2  respeten que gente de poca mente superenlo no ...         ira  politica\n",
      "3  lo dice un dinosaurio de la politica venezolan...         ira  politica\n",
      "4  que insistencia la de caramelo de colaborar co...         ira  politica\n",
      "El dataset preprocesado ha sido guardado como 'dataset1.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('dataset_preprocesado.csv')  # Aseg√∫rate de que el archivo est√© en la ruta correcta\n",
    "\n",
    "# Verificar la estructura del dataset\n",
    "print(df.head())\n",
    "\n",
    "# Funci√≥n para preprocesar los comentarios: eliminar comillas triples, poner comillas dobles y limpiar el texto\n",
    "def preprocesar_comentarios(comment):\n",
    "    # Paso 1: Eliminar comillas triples (si existen)\n",
    "    comment = re.sub(r'^\"\"\"(.*)\"\"\"$', r'\"\\1\"', comment)  # Eliminar comillas triples y reemplazar por comillas dobles\n",
    "    \n",
    "    # Paso 2: Eliminar comillas dobles al principio y al final (si ya las tiene)\n",
    "    comment = re.sub(r\"^['\\\"](.*)['\\\"]$\", r\"\\1\", comment)  # Elimina las comillas al inicio y fin\n",
    "    \n",
    "    # Paso 3: Convertir el texto a min√∫sculas\n",
    "    comment = comment.lower()\n",
    "    \n",
    "    # Paso 4: Eliminar caracteres no deseados, pero conservar los emojis\n",
    "    comment = re.sub(r'[^a-zA-Z0-9\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702\\U00002705\\U0000270A\\U0000270B\\U0001F004\\U0001F0CF]', '', comment)\n",
    "    \n",
    "\n",
    "    \n",
    "    return comment\n",
    "\n",
    "# Aplicar la funci√≥n de preprocesamiento a la columna 'comment'\n",
    "df['comment'] = df['comment'].apply(preprocesar_comentarios)\n",
    "\n",
    "# Verificar el dataset despu√©s del preprocesamiento\n",
    "print(df.head())\n",
    "\n",
    "# Guardar el dataset preprocesado\n",
    "df.to_csv('datase1.csv', index=False)\n",
    "\n",
    "print(\"El dataset preprocesado ha sido guardado como 'dataset1.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet sentimiento      tema\n",
      "0  Abajo La Dictadura de Maduro venezuela libre  ...         ira  politica\n",
      "1  Luz para afuera y oscuridad para la casa. Vene...         ira  politica\n",
      "2  El 1 de Diciembre movilizaci√≥n en  Venezuela  ...         ira  politica\n",
      "3  Siempre Confiando en ti. Vamos a lograrlo todo...     alegria  politica\n",
      "4  Una anciana apenas capaz de caminar se esforz√≥...    sorpresa  politica\n",
      "                                               tweet sentimiento      tema\n",
      "0  abajo la dictadura de maduro venezuela libre  ...         ira  politica\n",
      "1  luz para afuera y oscuridad para la casa venez...         ira  politica\n",
      "2  el 1 de diciembre movilizacin en  venezuela  y...         ira  politica\n",
      "3  siempre confiando en ti vamos a lograrlo todos...     alegria  politica\n",
      "4  una anciana apenas capaz de caminar se esforz ...    sorpresa  politica\n",
      "El dataset preprocesado ha sido guardado como 'dataset2.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('TweetsExtraidosLimpios.csv')  # Aseg√∫rate de que el archivo est√© en la ruta correcta\n",
    "\n",
    "# Verificar la estructura del dataset\n",
    "print(df.head())\n",
    "\n",
    "# Funci√≥n para preprocesar los comentarios: eliminar comillas, convertir a min√∫sculas y limpiar caracteres no deseados\n",
    "def preprocesar_comentarios(tweet):\n",
    "    # Paso 1: Eliminar comillas dobles o simples al principio y al final (si ya las tiene)\n",
    "    tweet = re.sub(r\"^['\\\"](.*)['\\\"]$\", r\"\\1\", tweet)  # Elimina las comillas al inicio y fin\n",
    "    \n",
    "    # Paso 2: Convertir el texto a min√∫sculas\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Paso 3: Eliminar caracteres no deseados, pero conservar los emojis\n",
    "    tweet = re.sub(r'[^a-zA-Z0-9\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702\\U00002705\\U0000270A\\U0000270B\\U0001F004\\U0001F0CF]', '', tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "# Limpiar las columnas 'sentimiento' y 'tema': eliminar espacios innecesarios\n",
    "df['sentimiento'] = df['sentimiento'].str.strip().str.replace(r'\\s+', ' ', regex=True)  # Eliminar espacios al inicio y fin, y reemplazar m√∫ltiples espacios por uno solo\n",
    "df['tema'] = df['tema'].str.strip().str.replace(r'\\s+', ' ', regex=True)  # Eliminar espacios al inicio y fin, y reemplazar m√∫ltiples espacios por uno solo\n",
    "\n",
    "# Aplicar la funci√≥n de preprocesamiento a la columna 'comment'\n",
    "df['tweet'] = df['tweet'].apply(preprocesar_comentarios)\n",
    "\n",
    "# Verificar el dataset despu√©s del preprocesamiento\n",
    "print(df.head())\n",
    "\n",
    "# Guardar el dataset limpio\n",
    "df.to_csv('dataset2.csv', index=False)\n",
    "\n",
    "print(\"El dataset preprocesado ha sido guardado como 'dataset2.csv'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en el dataset de entrenamiento:\n",
      "sentimiento    0\n",
      "tema           0\n",
      "dtype: int64\n",
      "Valores nulos en el dataset de validaci√≥n:\n",
      "sentimiento    0\n",
      "tema           0\n",
      "dtype: int64\n",
      "Filas con valores nulos en 'tema' en el dataset de entrenamiento:\n",
      "Empty DataFrame\n",
      "Columns: [comment, sentimiento, tema]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('datase1.csv')\n",
    "# Verificar si hay valores nulos en las columnas de sentimiento y tema\n",
    "print(\"Valores nulos en el dataset de entrenamiento:\")\n",
    "print(df[['sentimiento', 'tema']].isnull().sum())\n",
    "\n",
    "print(\"Valores nulos en el dataset de validaci√≥n:\")\n",
    "print(df[['sentimiento', 'tema']].isnull().sum())\n",
    "\n",
    "\n",
    "# Verificar las filas con valores nulos en la columna 'tema' para el dataset de entrenamiento\n",
    "print(\"Filas con valores nulos en 'tema' en el dataset de entrenamiento:\")\n",
    "print(df[df['tema'].isnull()])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en el dataset de entrenamiento despu√©s de la eliminaci√≥n:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Eliminar las filas con valores nulos en la columna 'tema' para el dataset de entrenamiento\n",
    "train_df = df.dropna(subset=['tema'])\n",
    "\n",
    "\n",
    "\n",
    "# Verificar que los valores nulos fueron eliminados\n",
    "print(\"Valores nulos en el dataset de entrenamiento despu√©s de la eliminaci√≥n:\")\n",
    "print(train_df['tema'].isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
